# transformer
transformer resources

参考文章：

[*BERT大火却不懂Transformer？读这一篇就够了*](https://zhuanlan.zhihu.com/p/54356280)

[*nlp中的Attention注意力机制+Transformer详解*](https://zhuanlan.zhihu.com/p/53682800)

[*深度学习中的注意力模型（2017版）*](https://zhuanlan.zhihu.com/p/37601161)

[*Attention机制详解（一）——Seq2Seq中的Attention*](https://zhuanlan.zhihu.com/p/47063917)

[*Attention机制详解（二）——Self-Attention与Transformer*](https://zhuanlan.zhihu.com/p/47282410)

[*Attention机制详解（三）——Attention模型的应用*](https://zhuanlan.zhihu.com/p/47613793)

[*一文看懂 Attention（本质原理+3大优点+5大类型*](https://zhuanlan.zhihu.com/p/91839581)

[*Attention机制从入门到精通*](https://zhuanlan.zhihu.com/p/78850152)


源码解析：


[*The Annotated Transformer*]（https://nlp.seas.harvard.edu/2018/04/03/attention.html）

[*The Annotated Transformer的中文注释版（1）*]（https://zhuanlan.zhihu.com/p/107889011）

[*The Annotated Transformer的中文注释版（2）*](https://zhuanlan.zhihu.com/p/107889011)

[*The Annotated Transformer的中文注释版（1）*](https://zhuanlan.zhihu.com/p/109003287)


